{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "syngap_path = '/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/Qualitycheck/SYNGAP1_T3_C1_08092024/Activity/Compiled_ActivityScan.csv'\n",
    "data=pd.read_csv(syngap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIV</th>\n",
       "      <th>Chip_ID</th>\n",
       "      <th>Well</th>\n",
       "      <th>NeuronType</th>\n",
       "      <th>Active_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>M05506</td>\n",
       "      <td>1</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>M05506</td>\n",
       "      <td>1</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>M05506</td>\n",
       "      <td>1</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>M05506</td>\n",
       "      <td>1</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>M05506</td>\n",
       "      <td>1</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>7</td>\n",
       "      <td>M06844</td>\n",
       "      <td>6</td>\n",
       "      <td>HET</td>\n",
       "      <td>12.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>11</td>\n",
       "      <td>M06844</td>\n",
       "      <td>6</td>\n",
       "      <td>HET</td>\n",
       "      <td>6.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>14</td>\n",
       "      <td>M06844</td>\n",
       "      <td>6</td>\n",
       "      <td>HET</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>18</td>\n",
       "      <td>M06844</td>\n",
       "      <td>6</td>\n",
       "      <td>HET</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>21</td>\n",
       "      <td>M06844</td>\n",
       "      <td>6</td>\n",
       "      <td>HET</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DIV Chip_ID  Well NeuronType  Active_area\n",
       "0      4  M05506     1         WT         0.43\n",
       "1      6  M05506     1         WT         0.24\n",
       "2      7  M05506     1         WT         0.22\n",
       "3     11  M05506     1         WT         0.00\n",
       "4     14  M05506     1         WT         0.00\n",
       "..   ...     ...   ...        ...          ...\n",
       "163    7  M06844     6        HET        12.23\n",
       "164   11  M06844     6        HET         6.24\n",
       "165   14  M06844     6        HET         5.33\n",
       "166   18  M06844     6        HET         2.32\n",
       "167   21  M06844     6        HET          NaN\n",
       "\n",
       "[168 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = data[(data['DIV'] >= 14) & (data['DIV'] <= 28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIV</th>\n",
       "      <th>Chip_ID</th>\n",
       "      <th>Well</th>\n",
       "      <th>NeuronType</th>\n",
       "      <th>Active_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>M05506</td>\n",
       "      <td>1</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>M05506</td>\n",
       "      <td>1</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>M05506</td>\n",
       "      <td>1</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>M05506</td>\n",
       "      <td>2</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>M05506</td>\n",
       "      <td>2</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>18</td>\n",
       "      <td>M06844</td>\n",
       "      <td>5</td>\n",
       "      <td>HET</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>21</td>\n",
       "      <td>M06844</td>\n",
       "      <td>5</td>\n",
       "      <td>HET</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>14</td>\n",
       "      <td>M06844</td>\n",
       "      <td>6</td>\n",
       "      <td>HET</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>18</td>\n",
       "      <td>M06844</td>\n",
       "      <td>6</td>\n",
       "      <td>HET</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>21</td>\n",
       "      <td>M06844</td>\n",
       "      <td>6</td>\n",
       "      <td>HET</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DIV Chip_ID  Well NeuronType  Active_area\n",
       "4     14  M05506     1         WT         0.00\n",
       "5     18  M05506     1         WT         0.00\n",
       "6     21  M05506     1         WT         0.00\n",
       "11    14  M05506     2         WT         0.00\n",
       "12    18  M05506     2         WT         0.00\n",
       "..   ...     ...   ...        ...          ...\n",
       "159   18  M06844     5        HET         3.51\n",
       "160   21  M06844     5        HET          NaN\n",
       "165   14  M06844     6        HET         5.33\n",
       "166   18  M06844     6        HET         2.32\n",
       "167   21  M06844     6        HET          NaN\n",
       "\n",
       "[72 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract WT\n",
    "WT = data_subset[data_subset['NeuronType'] == 'WT']\n",
    "# drop rows with Active_Area with NaN values\n",
    "WT = WT.dropna(subset=['Active_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M05506', 'M08024', 'M08034', 'M06844'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chip_ids = WT['Chip_ID'].unique()\n",
    "chip_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is not qualified. More than 50% of lines show low activity (<50%).\n",
      "Percentage of qualified lines: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Define the criteria for filtering: lines with Activity_area < 50, filter out if 50% of WT units exhibit lower than 50% activity area\n",
    "\n",
    "criteria = 50\n",
    "\n",
    "# Group by 'Chip_ID','Well','DIV' and calculate the percentage of rows with 'Active_area' < 50 for each combination\n",
    "grouped_by_run = WT.groupby(['Chip_ID','Well','DIV'])['Active_area'].apply(lambda x: (x < criteria).mean())\n",
    "\n",
    "# Calculate the percentage of lines with low activity\n",
    "percentage_low_activity_run_ids = (grouped_by_run > 0.5).mean() * 100\n",
    "\n",
    "# Calculate the percentage of qualified lines\n",
    "percentage_qualified_run_ids = 100 - percentage_low_activity_run_ids\n",
    "\n",
    "# Determine if the dataset is qualified or not based on the criteria\n",
    "if percentage_low_activity_run_ids > 50:\n",
    "    print(\"The dataset is not qualified. More than 50% of lines show low activity (<50%).\")\n",
    "else:\n",
    "    print(\"The dataset is qualified. Less than or equal to 50% of lines show low activity (<50).\")\n",
    "\n",
    "# Print the percentage of qualified lines\n",
    "print(f\"Percentage of qualified lines: {percentage_qualified_run_ids:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chip_ID  Well  DIV\n",
       "M05506   1     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "         2     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "         3     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "M06844   1     14     1.0\n",
       "               18     1.0\n",
       "               21     0.0\n",
       "         2     14     1.0\n",
       "               18     1.0\n",
       "               21     0.0\n",
       "         3     14     1.0\n",
       "               18     1.0\n",
       "               21     0.0\n",
       "M08024   1     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "         2     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "         3     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "M08034   1     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "         2     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "         3     14     1.0\n",
       "               18     1.0\n",
       "               21     1.0\n",
       "Name: Active_area, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_by_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_datasets(file_paths):\n",
    "    \"\"\"\n",
    "    Batch process multiple datasets to check their qualification based on the criteria \n",
    "    that less than or equal to 50% of unique lines exhibit more than 50% of rows with low activity (<50).\n",
    "\n",
    "    Parameters:\n",
    "    - file_paths (list of str): List of paths to CSV files.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary with file paths as keys and tuples as values containing the qualification message\n",
    "            and the percentage of qualified lines for each dataset.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Function to process each file and determine qualification\n",
    "    def process_single_file(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        WT = data[data['NeuronType'] == 'WT']\n",
    "        criteria = 50\n",
    "        grouped_by_run = WT.groupby('Run_ID')['Active_area'].apply(lambda x: (x < criteria).mean())\n",
    "        percentage_low_activity_run_ids = (grouped_by_run > 0.5).mean() * 100\n",
    "        percentage_qualified_run_ids = 100 - percentage_low_activity_run_ids\n",
    "        \n",
    "        if percentage_low_activity_run_ids > 50:\n",
    "            result_message = \"The dataset is not qualified. More than 50% of lines show low activity (<50).\"\n",
    "        else:\n",
    "            result_message = \"The dataset is qualified. Less than or equal to 50% of lines show low activity (<50).\"\n",
    "        \n",
    "        return result_message, percentage_qualified_run_ids\n",
    "\n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "    \n",
    "    # Process each file and store the result\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            results[path] = process_single_file(path)\n",
    "        except Exception as e:\n",
    "            results[path] = (f\"Error processing file: {str(e)}\", None)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/Outputs/SYNGAP_T1_ALL/Activity/Compiled_ActivityScan.csv\n",
      "The dataset is not qualified. More than 50% of lines show low activity (<50).\n",
      "Percentage of qualified lines: 39.29%\n",
      "---\n",
      "File: /Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/Outputs/SYNGAP_T1/Activity/Compiled_ActivityScan.csv\n",
      "The dataset is not qualified. More than 50% of lines show low activity (<50).\n",
      "Percentage of qualified lines: 43.75%\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Example usage with a list of file paths\n",
    "file_paths = ['/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/QualityCheck/SYNGAP_T1_ALL/Activity/Compiled_ActivityScan.csv', \n",
    "              '/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/QualityCheck/SYNGAP_T1/Activity/Compiled_ActivityScan.csv']  # Add more file paths as needed\n",
    "batch_results = batch_process_datasets(file_paths)\n",
    "\n",
    "# Display results for each file processed\n",
    "for path, (message, percentage) in batch_results.items():\n",
    "    print(f\"File: {path}\")\n",
    "    print(message)\n",
    "    if percentage is not None:\n",
    "        print(f\"Percentage of qualified lines: {percentage:.2f}%\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_process_activity_data(base_path):\n",
    "    \"\"\"\n",
    "    Recursively find and process 'Compiled_ActivityScan.csv' in each 'Activity' subfolder\n",
    "    within the given base directory.\n",
    "    \n",
    "    Parameters:\n",
    "    - base_path (str): The base directory to start the search from.\n",
    "    \n",
    "    Returns:\n",
    "    - None: Results are printed directly.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    def process_single_file(file_path):\n",
    "        try:\n",
    "            data = pd.read_csv(file_path)\n",
    "            if 'WT' not in data['NeuronType'].unique():\n",
    "                return (\"Missing WT data.\", \"nan%\")\n",
    "\n",
    "            WT = data[data['NeuronType'] == 'WT']\n",
    "            if WT.empty:\n",
    "                return (\"Missing WT data.\", \"nan%\")\n",
    "\n",
    "            criteria = 50\n",
    "            grouped_by_run = WT.groupby(['Chip_ID','Well','DIV'])['Active_area'].apply(lambda x: (x < criteria).mean())\n",
    "            percentage_low_activity_run_ids = (grouped_by_run > 0.5).mean() * 100\n",
    "            percentage_qualified_run_ids = 100 - percentage_low_activity_run_ids\n",
    "            \n",
    "            if percentage_low_activity_run_ids > 50:\n",
    "                result_message = \"The dataset is not qualified. More than 50% of lines show low activity (<50%).\"\n",
    "            else:\n",
    "                result_message = \"The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%).\"\n",
    "            \n",
    "            return (result_message, f\"{percentage_qualified_run_ids:.2f}%\")\n",
    "        except Exception as e:\n",
    "            return (f\"Error processing file: {str(e)}\", None)\n",
    "\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        if 'Activity' in dirs:\n",
    "            activity_path = os.path.join(root, 'Activity')\n",
    "            csv_file = os.path.join(activity_path, 'Compiled_ActivityScan.csv')\n",
    "            subfolder_name = root.split(os.sep)[-1]\n",
    "            \n",
    "            if os.path.exists(csv_file):\n",
    "                result = process_single_file(csv_file)\n",
    "                print(f\"{subfolder_name}: {result[0]} Percentage of qualified lines: {result[1]}\")\n",
    "            else:\n",
    "                print(f\"{subfolder_name}: Missing 'Compiled_ActivityScan.csv'\")\n",
    "        else:\n",
    "            if root.count(os.sep) - base_path.count(os.sep) == 1:  # Only report missing in direct subfolders of base_path\n",
    "                subfolder_name = root.split(os.sep)[-1]\n",
    "                print(f\"{subfolder_name}: Missing 'Activity' folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADNP_Therapy_T2: Missing WT data. Percentage of qualified lines: nan%\n",
      "SYNGAP_T1_ALL: The dataset is not qualified. More than 50% of lines show low activity (<50%). Percentage of qualified lines: 34.38%\n",
      "TEST: Missing 'Activity' folder\n",
      "SYNGAP_T1: The dataset is not qualified. More than 50% of lines show low activity (<50%). Percentage of qualified lines: 43.75%\n",
      "SYNGAP_Therapy_T1: The dataset is not qualified. More than 50% of lines show low activity (<50%). Percentage of qualified lines: 25.00%\n",
      "SYNGAP_T2: Missing WT data. Percentage of qualified lines: nan%\n",
      "TEST_2: Missing 'Activity' folder\n",
      "whatever: Missing WT data. Percentage of qualified lines: nan%\n"
     ]
    }
   ],
   "source": [
    "# Uprated Example usage\n",
    "base_path = \"/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/QualityCheck\"\n",
    "find_and_process_activity_data(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final function, with saving results to CSV files, and limited the certain div range\n",
    "def find_and_process_activity_data(base_path):\n",
    "    \"\"\"\n",
    "    Recursively find and process 'Compiled_ActivityScan.csv' in each 'Activity' subfolder\n",
    "    within the given base directory. Outputs two CSV files listing eligible and ineligible subfolders\n",
    "    with their corresponding percentages of qualified lines.\n",
    "    \n",
    "    Parameters:\n",
    "    - base_path (str): The base directory to start the search from.\n",
    "    \n",
    "    Returns:\n",
    "    - None: Results are printed directly and saved into CSV files.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    eligible = []\n",
    "    ineligible = []\n",
    "    \n",
    "    def process_single_file(file_path):\n",
    "        try:\n",
    "            data = pd.read_csv(file_path)\n",
    "            data_subset = data[(data['DIV'] >= 14) & (data['DIV'] <= 28)]\n",
    "            if 'WT' not in data_subset['NeuronType'].unique() or data_subset[data_subset['NeuronType'] == 'WT'].empty:\n",
    "                return (\"Missing WT data.\", \"nan\", False)\n",
    "\n",
    "            WT = data_subset[data_subset['NeuronType'] == 'WT']\n",
    "            WT = WT.dropna(subset=['Active_area'])\n",
    "            criteria = 50\n",
    "            grouped_by_run = WT.groupby(['Chip_ID','Well','DIV'])['Active_area'].apply(lambda x: (x < criteria).mean())\n",
    "            percentage_low_activity_lines = (grouped_by_run > 0.5).mean() * 100\n",
    "            percentage_qualified_lines = 100 - percentage_low_activity_lines\n",
    "            \n",
    "            if percentage_low_activity_lines > 50:\n",
    "                result_message = \"The dataset is not qualified. More than 50% of lines show low activity (<50%).\"\n",
    "                return (result_message, f\"{percentage_qualified_lines:.2f}%\", False)\n",
    "            else:\n",
    "                result_message = \"The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%).\"\n",
    "                return (result_message, f\"{percentage_qualified_lines:.2f}%\", True)\n",
    "        except Exception as e:\n",
    "            return (f\"Error processing file: {str(e)}\", \"nan\", False)\n",
    "\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        subfolder_name = root.split(os.sep)[-1]\n",
    "        if 'Activity' in dirs:\n",
    "            activity_path = os.path.join(root, 'Activity')\n",
    "            csv_file = os.path.join(activity_path, 'Compiled_ActivityScan.csv')\n",
    "            \n",
    "            if os.path.exists(csv_file):\n",
    "                result = process_single_file(csv_file)\n",
    "                print(f\"{subfolder_name}: {result[0]} Percentage of qualified lines: {result[1]}\")\n",
    "                if result[2]:\n",
    "                    eligible.append((subfolder_name, result[1]))\n",
    "                else:\n",
    "                    ineligible.append((subfolder_name, result[1]))\n",
    "            else:\n",
    "                print(f\"{subfolder_name}: Missing 'Compiled_ActivityScan.csv'\")\n",
    "                ineligible.append((subfolder_name, \"nan\"))\n",
    "        else:\n",
    "            if root.count(os.sep) - base_path.count(os.sep) == 1:  # Only report missing in direct subfolders of base_path\n",
    "                print(f\"{subfolder_name}: Missing 'Activity' folder\")\n",
    "                ineligible.append((subfolder_name, \"nan\"))\n",
    "    \n",
    "    # Save results to CSV files\n",
    "    pd.DataFrame(eligible, columns=['Subfolder', 'Percentage of Qualified Lines']).to_csv(os.path.join(base_path, 'Eligible_Cohorts.csv'), index=False)\n",
    "    pd.DataFrame(ineligible, columns=['Subfolder', 'Percentage of Qualified Lines']).to_csv(os.path.join(base_path, 'Ineligible_Cohorts.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDKL5-E6D_T1_C1_05152024: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n",
      "SYNGAP1_T1_C1_03212024: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 93.75%\n",
      "B6J Hyb: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 58.33%\n",
      "SYNGAP1_T3_C1_08092024: The dataset is not qualified. More than 50% of lines show low activity (<50%). Percentage of qualified lines: 0.00%\n",
      "B6J_T1_02232024_PS: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 58.33%\n",
      "KCNT1_T3_C1_03122024: The dataset is not qualified. More than 50% of lines show low activity (<50%). Percentage of qualified lines: 10.00%\n",
      "ADNP_T2: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n",
      "CDKL5-E6D_T2_C1_05212024: The dataset is not qualified. More than 50% of lines show low activity (<50%). Percentage of qualified lines: 31.25%\n",
      "ADNP_T3: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n",
      "SHANK3_1: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n",
      "CHD8_T4_C2_02082024: The dataset is not qualified. More than 50% of lines show low activity (<50%). Percentage of qualified lines: 9.38%\n",
      "ADNP_T4_C1_06282024: The dataset is qualified. Less than or equal to 50% of lines show low activity (<50%). Percentage of qualified lines: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "base_path = \"/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/QualityCheck\"\n",
    "find_and_process_activity_data(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tunning parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
