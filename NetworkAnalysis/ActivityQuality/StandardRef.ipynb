{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hz/mtvvz9t52kxgqcx423vlrhx00000gn/T/ipykernel_70775/97710178.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  general_info_df['Mapping_Key'] = general_info_df.apply(lambda x: f'P{x[\"Plate #\"]}W{x[\"Well #\"]}', axis=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the simple_check.csv to examine its contents\n",
    "simple_check_path = '/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/QualityCheck/simple_check.csv'\n",
    "simple_check_df = pd.read_csv(simple_check_path)\n",
    "\n",
    "# Identify the index where the second part starts by locating the header \"P1W1\"\n",
    "active_area_start_idx = simple_check_df[simple_check_df.eq(\"P1W1\").any(axis=1)].index.min()  # Corrected to specify axis as keyword argument\n",
    "\n",
    "# Extract the general information data and the active area data separately\n",
    "general_info_df = simple_check_df.iloc[:active_area_start_idx]\n",
    "active_area_df = simple_check_df.iloc[active_area_start_idx + 1:]  # skip the row with headers\n",
    "active_area_df.columns = simple_check_df.iloc[active_area_start_idx]  # Set new header for active area data\n",
    "\n",
    "# Construct correct keys for the mapping\n",
    "general_info_df['Mapping_Key'] = general_info_df.apply(lambda x: f'P{x[\"Plate #\"]}W{x[\"Well #\"]}', axis=1)\n",
    "well_plate_genotype_mapping = general_info_df.set_index('Mapping_Key')[['Plate ID', 'Genotype']]\n",
    "\n",
    "# Create the new DataFrame structured as per the requirements\n",
    "new_csv_data = []\n",
    "for column in active_area_df.columns[2:]:  # skip 'Date' and 'DIV' columns\n",
    "    for index, row in active_area_df.iterrows():\n",
    "        if column in well_plate_genotype_mapping.index:\n",
    "            plate_id = well_plate_genotype_mapping.loc[column, 'Plate ID']\n",
    "            genotype = well_plate_genotype_mapping.loc[column, 'Genotype']\n",
    "            new_csv_data.append({\n",
    "                'DIV': row['DIV'],\n",
    "                'Chip_ID': plate_id,\n",
    "                'Well': column,\n",
    "                'NeuronType': genotype,\n",
    "                'Active_area': row[column]\n",
    "            })\n",
    "\n",
    "# Convert list of dictionaries into a DataFrame\n",
    "new_csv_df = pd.DataFrame(new_csv_data)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "new_csv_path = '/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/QualityCheck/standardized_simple_check.csv'\n",
    "new_csv_df.to_csv(new_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIV</th>\n",
       "      <th>Chip_ID</th>\n",
       "      <th>Well</th>\n",
       "      <th>NeuronType</th>\n",
       "      <th>Active_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>M05506</td>\n",
       "      <td>P1W1</td>\n",
       "      <td>WT1</td>\n",
       "      <td>51.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>M05506</td>\n",
       "      <td>P1W1</td>\n",
       "      <td>WT1</td>\n",
       "      <td>80.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>M05506</td>\n",
       "      <td>P1W1</td>\n",
       "      <td>WT1</td>\n",
       "      <td>92.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>M05506</td>\n",
       "      <td>P1W1</td>\n",
       "      <td>WT1</td>\n",
       "      <td>95.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>M05506</td>\n",
       "      <td>P1W1</td>\n",
       "      <td>WT1</td>\n",
       "      <td>95.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>18</td>\n",
       "      <td>M07309</td>\n",
       "      <td>P5W3</td>\n",
       "      <td>WT2</td>\n",
       "      <td>93.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>21</td>\n",
       "      <td>M07309</td>\n",
       "      <td>P5W3</td>\n",
       "      <td>WT2</td>\n",
       "      <td>94.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>25</td>\n",
       "      <td>M07309</td>\n",
       "      <td>P5W3</td>\n",
       "      <td>WT2</td>\n",
       "      <td>92.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>27</td>\n",
       "      <td>M07309</td>\n",
       "      <td>P5W3</td>\n",
       "      <td>WT2</td>\n",
       "      <td>90.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>32</td>\n",
       "      <td>M07309</td>\n",
       "      <td>P5W3</td>\n",
       "      <td>WT2</td>\n",
       "      <td>92.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    DIV Chip_ID  Well NeuronType Active_area\n",
       "0     7  M05506  P1W1        WT1       51.05\n",
       "1    11  M05506  P1W1        WT1       80.65\n",
       "2    14  M05506  P1W1        WT1       92.98\n",
       "3    18  M05506  P1W1        WT1       95.61\n",
       "4    21  M05506  P1W1        WT1       95.62\n",
       "..   ..     ...   ...        ...         ...\n",
       "163  18  M07309  P5W3        WT2       93.73\n",
       "164  21  M07309  P5W3        WT2       94.73\n",
       "165  25  M07309  P5W3        WT2       92.56\n",
       "166  27  M07309  P5W3        WT2       90.42\n",
       "167  32  M07309  P5W3        WT2       92.88\n",
       "\n",
       "[168 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hz/mtvvz9t52kxgqcx423vlrhx00000gn/T/ipykernel_70775/2877308360.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  general_info_df['Mapping_Key'] = general_info_df.apply(lambda x: f'P{x[\"Plate #\"]}W{x[\"Well #\"]}', axis=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the simple_check.csv to examine its contents\n",
    "simple_check_path = '/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/QualityCheck/simple_check.csv'\n",
    "simple_check_df = pd.read_csv(simple_check_path)\n",
    "\n",
    "# Identify the index where the second part starts by locating the header \"P1W1\"\n",
    "active_area_start_idx = simple_check_df[simple_check_df.eq(\"P1W1\").any(axis=1)].index.min()\n",
    "\n",
    "# Extract the general information data and the active area data separately\n",
    "general_info_df = simple_check_df.iloc[:active_area_start_idx]\n",
    "active_area_df = simple_check_df.iloc[active_area_start_idx + 1:]  # skip the row with headers\n",
    "active_area_df.columns = simple_check_df.iloc[active_area_start_idx]  # Set new header for active area data\n",
    "\n",
    "# Construct correct keys for the mapping\n",
    "general_info_df['Mapping_Key'] = general_info_df.apply(lambda x: f'P{x[\"Plate #\"]}W{x[\"Well #\"]}', axis=1)\n",
    "well_plate_genotype_mapping = general_info_df.set_index('Mapping_Key')[['Plate ID', 'Genotype']]\n",
    "\n",
    "# Create the new DataFrame structured as per the requirements\n",
    "new_csv_data = []\n",
    "for column in active_area_df.columns[2:]:  # skip 'Date' and 'DIV' columns\n",
    "    for index, row in active_area_df.iterrows():\n",
    "        if column in well_plate_genotype_mapping.index:\n",
    "            plate_id = well_plate_genotype_mapping.loc[column, 'Plate ID']\n",
    "            genotype = well_plate_genotype_mapping.loc[column, 'Genotype']\n",
    "            well_number = column[-1]  # Extract the last character, which is the well number\n",
    "            new_csv_data.append({\n",
    "                'DIV': row['DIV'],\n",
    "                'Chip_ID': plate_id,\n",
    "                'Well': well_number,  # Use the extracted well number\n",
    "                'NeuronType': genotype,\n",
    "                'Active_area': row[column]\n",
    "            })\n",
    "\n",
    "# Convert list of dictionaries into a DataFrame\n",
    "new_csv_df = pd.DataFrame(new_csv_data)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "new_csv_path = '/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/QualityCheck/standardized_simple_check.csv'\n",
    "new_csv_df.to_csv(new_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hz/mtvvz9t52kxgqcx423vlrhx00000gn/T/ipykernel_70775/3689096833.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  general_info_df['Mapping_Key'] = general_info_df.apply(lambda x: f'P{x[\"Plate #\"]}W{x[\"Well #\"]}', axis=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the simple_check.csv to examine its contents\n",
    "simple_check_path = '/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/QualityCheck/simple_check.csv'\n",
    "simple_check_df = pd.read_csv(simple_check_path)\n",
    "\n",
    "# Identify the index where the second part starts by locating the header \"P1W1\"\n",
    "active_area_start_idx = simple_check_df[simple_check_df.eq(\"P1W1\").any(axis=1)].index.min()\n",
    "\n",
    "# Extract the general information data and the active area data separately\n",
    "general_info_df = simple_check_df.iloc[:active_area_start_idx]\n",
    "active_area_df = simple_check_df.iloc[active_area_start_idx + 1:]  # skip the row with headers\n",
    "active_area_df.columns = simple_check_df.iloc[active_area_start_idx]  # Set new header for active area data\n",
    "\n",
    "# Construct correct keys for the mapping\n",
    "general_info_df['Mapping_Key'] = general_info_df.apply(lambda x: f'P{x[\"Plate #\"]}W{x[\"Well #\"]}', axis=1)\n",
    "well_plate_genotype_mapping = general_info_df.set_index('Mapping_Key')[['Plate ID', 'Genotype']]\n",
    "\n",
    "# Create the new DataFrame structured as per the requirements\n",
    "new_csv_data = []\n",
    "for column in active_area_df.columns[2:]:  # skip 'Date' and 'DIV' columns\n",
    "    for index, row in active_area_df.iterrows():\n",
    "        if column in well_plate_genotype_mapping.index:\n",
    "            plate_id = well_plate_genotype_mapping.loc[column, 'Plate ID']\n",
    "            genotype = well_plate_genotype_mapping.loc[column, 'Genotype']\n",
    "            well_number = column[-1]  # Extract the last character, which is the well number\n",
    "            # Standardize NeuronType for any genotype containing \"WT\"\n",
    "            neuron_type = \"WT\" if \"WT\" in genotype else genotype\n",
    "            new_csv_data.append({\n",
    "                'DIV': row['DIV'],\n",
    "                'Chip_ID': plate_id,\n",
    "                'Well': well_number,  # Use the extracted well number\n",
    "                'NeuronType': neuron_type,\n",
    "                'Active_area': row[column]\n",
    "            })\n",
    "\n",
    "# Convert list of dictionaries into a DataFrame\n",
    "new_csv_df = pd.DataFrame(new_csv_data)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "new_csv_path = '/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/QualityCheck/Compiled_ActivityScan.csv'\n",
    "new_csv_df.to_csv(new_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete. Files have been saved in their respective directories.\n"
     ]
    }
   ],
   "source": [
    "# # spike only and full trace analysis\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import re  # Import the regular expression library\n",
    "\n",
    "# # Define the base path for saving the results\n",
    "# base_path = '/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/SpikeOnly_FullTrace_check'\n",
    "\n",
    "# # Load the Excel file\n",
    "# excel_path = '/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/SpikeOnly_FullTrace_check/HET.xlsx'\n",
    "# sheets = pd.read_excel(excel_path, sheet_name=None)  # Load all sheets into a dictionary\n",
    "\n",
    "# # Process each sheet\n",
    "# for sheet_name, simple_check_df in sheets.items():\n",
    "#     # Identify the index where the second part starts by locating the header \"P1W1\"\n",
    "#     active_area_start_idx = simple_check_df[simple_check_df.eq(\"P1W4\").any(axis=1)].index.min()\n",
    "\n",
    "#     # Extract the general information data and the active area data separately, making a copy to avoid SettingWithCopyWarning\n",
    "#     general_info_df = simple_check_df.iloc[:active_area_start_idx].copy()\n",
    "#     active_area_df = simple_check_df.iloc[active_area_start_idx + 1:].copy()  # skip the row with headers and make a copy\n",
    "#     active_area_df.columns = simple_check_df.iloc[active_area_start_idx]  # Set new header for active area data\n",
    "\n",
    "#     # Construct correct keys for the mapping\n",
    "#     general_info_df['Mapping_Key'] = general_info_df.apply(lambda x: f'P{x[\"Plate #\"]}W{x[\"Well #\"]}', axis=1)\n",
    "#     well_plate_genotype_mapping = general_info_df.set_index('Mapping_Key')[['Plate ID', 'Genotype']]\n",
    "\n",
    "#     # Create the new DataFrame structured as per the requirements\n",
    "#     new_csv_data = []\n",
    "#     for column in active_area_df.columns[2:]:  # skip 'Date' and 'DIV' columns\n",
    "#         for index, row in active_area_df.iterrows():\n",
    "#             if column in well_plate_genotype_mapping.index:\n",
    "#                 plate_id = well_plate_genotype_mapping.loc[column, 'Plate ID']\n",
    "#                 genotype = well_plate_genotype_mapping.loc[column, 'Genotype']\n",
    "#                 # Use regex to extract the well number (handles one or two digits)\n",
    "#                 well_number = re.search('W(\\d+)', column).group(1)\n",
    "#                 # Standardize NeuronType for any genotype containing \"WT\"\n",
    "#                 neuron_type = \"WT\" if \"WT\" in genotype else genotype\n",
    "#                 new_csv_data.append({\n",
    "#                     'DIV': row['DIV'],\n",
    "#                     'Chip_ID': plate_id,\n",
    "#                     'Well': well_number,\n",
    "#                     'NeuronType': neuron_type,\n",
    "#                     'Active_area': row[column]\n",
    "#                 })\n",
    "\n",
    "#     # Convert list of dictionaries into a DataFrame\n",
    "#     new_csv_df = pd.DataFrame(new_csv_data)\n",
    "\n",
    "#     # Define the full path for saving the file\n",
    "#     full_path = os.path.join(base_path, sheet_name, 'Activity', 'Compiled_ActivityScan.csv')\n",
    "#     os.makedirs(os.path.dirname(full_path), exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "#     # Save the DataFrame to a new CSV file\n",
    "#     new_csv_df.to_csv(full_path, index=False)\n",
    "\n",
    "# print(\"Data processing complete. Files have been saved in their respective directories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete. Files have been saved in their respective directories.\n"
     ]
    }
   ],
   "source": [
    "# final version\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the base path for saving the results\n",
    "base_path = '/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/QualityCheck'\n",
    "\n",
    "# Load the Excel file\n",
    "excel_path = '/Users/liufanling/Library/CloudStorage/OneDrive-Personal/1 UC DAVIS/2024 Summer/CSRA/QualityCheck/simple_check.xlsx'\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)  # Load all sheets into a dictionary\n",
    "\n",
    "# Process each sheet\n",
    "for sheet_name, simple_check_df in sheets.items():\n",
    "    # Identify the index where the second part starts by locating the header \"P1W1\"\n",
    "    active_area_start_idx = simple_check_df[simple_check_df.eq(\"P1W1\").any(axis=1)].index.min()\n",
    "\n",
    "    # Extract the general information data and the active area data separately, making a copy to avoid SettingWithCopyWarning\n",
    "    general_info_df = simple_check_df.iloc[:active_area_start_idx].copy()\n",
    "    active_area_df = simple_check_df.iloc[active_area_start_idx + 1:].copy()  # skip the row with headers and make a copy\n",
    "    active_area_df.columns = simple_check_df.iloc[active_area_start_idx]  # Set new header for active area data\n",
    "\n",
    "    # Construct correct keys for the mapping\n",
    "    general_info_df['Mapping_Key'] = general_info_df.apply(lambda x: f'P{x[\"Plate #\"]}W{x[\"Well #\"]}', axis=1)\n",
    "    well_plate_genotype_mapping = general_info_df.set_index('Mapping_Key')[['Plate ID', 'Genotype']]\n",
    "\n",
    "    # Create the new DataFrame structured as per the requirements\n",
    "    new_csv_data = []\n",
    "    for column in active_area_df.columns[2:]:  # skip 'Date' and 'DIV' columns\n",
    "        for index, row in active_area_df.iterrows():\n",
    "            if column in well_plate_genotype_mapping.index:\n",
    "                plate_id = well_plate_genotype_mapping.loc[column, 'Plate ID']\n",
    "                genotype = well_plate_genotype_mapping.loc[column, 'Genotype']\n",
    "                well_number = column[-1]  # Extract the last character, which is the well number\n",
    "                # Standardize NeuronType for any genotype containing \"WT\"\n",
    "                neuron_type = \"WT\" if \"WT\" in genotype else genotype\n",
    "                new_csv_data.append({\n",
    "                    'DIV': row['DIV'],\n",
    "                    'Chip_ID': plate_id,\n",
    "                    'Well': well_number,\n",
    "                    'NeuronType': neuron_type,\n",
    "                    'Active_area': row[column]\n",
    "                })\n",
    "\n",
    "    # Convert list of dictionaries into a DataFrame\n",
    "    new_csv_df = pd.DataFrame(new_csv_data)\n",
    "\n",
    "    # Define the full path for saving the file\n",
    "    full_path = os.path.join(base_path, sheet_name, 'Activity', 'Compiled_ActivityScan.csv')\n",
    "    os.makedirs(os.path.dirname(full_path), exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "    # Save the DataFrame to a new CSV file\n",
    "    new_csv_df.to_csv(full_path, index=False)\n",
    "\n",
    "print(\"Data processing complete. Files have been saved in their respective directories.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
